# -*- coding: utf-8 -*-
"""Project_Finance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v6JhmzfY8MsEJBXKrgOqRY_qjXkmSQcm

- Project Title : (Finance Domain) Utilizing Machine Learning to Forecast the Probability of Successfully Collecting Debts by Analyzing Statute-Barred Status

- Problem Statement : In the realm of debt collection, the ability to discern which accounts are statute-barred—thus potentially unrecoverable—holds immense significance. This project endeavors to develop a sophisticated machine-learning model aimed at accurately predicting the probability of successfully collecting debts by meticulously examining the statute-barred status of each account.
Given a dataset encompassing a multitude of attributes including original creditor information, account IDs, current balances, purchase dates, and a wealth of other pertinent features, the objective is to construct a predictive model that excels in identifying accounts where the statute barred status may influence the likelihood of debt retrieval.
The focal point of this endeavor centers on the IsStatBarred field ‘Y’ status, which serves as the pivotal target variable for classification.

- DataSet Description : Dataset has 406424 rows and 22 columns
Column Descriptions are as follow:

1. EntityID: Unique identifier for each entry.
2. OriginalCreditor[Redacted]: Name of the original creditor, with sensitive information redacted.
3. AccountID: Unique identifier for the account.
4. Current Balance: The current balance of the account.
5. DebtLoadPrincipal: The principal amount of the debt load.
6. BalanceAtDebtLoad: The balance at the time of debt load.
7. PurchasePrice: The price at which the debt was purchased.
8. ProductOrDebtType: Type of product or debt.
9. CollectionStatus: Status of the debt collection
10. Closure Reason: Reason for closing the account.
11. InBankruptcy: Indicates if the account is involved in bankruptcy.
12. AccountInsolvencyType: Type of insolvency related to the account.
13. CustomerInsolvencyType: Type of insolvency related to the customer.
14. IsLegal: Indicates if legal action has been taken.
15. LastPaymentAmount: Amount of the last payment made.
16. LastPaymentMethod: Method used for the last payment.
17. NumLiableParties: Number of liable parties associated with the account.
18. CustomerAge: Age of the customer.
19. NumPhones: Number of phone contacts associated with the customer.
20. NumEmails: Number of email contacts associated with the customer.
21. NumAddresses: Number of addresses associated with the customer.
22. IsStatBarred: Indicates if the debt is statute-barred.
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix
from sklearn.impute import KNNImputer
from sklearn.model_selection import cross_val_score

"""- Pandas & Numpy: Used for data manipulation and numerical operations.
- Seaborn & Matplotlib: For creating various plots and visualizations.
- Scikit-learn: For machine learning algorithms and utilities like splitting data, scaling, encoding, and more.
- Imbalanced-learn (imblearn): For handling class imbalance using SMOTE (Synthetic Minority Over-sampling Technique).
- Ensemble models: RandomForestClassifier GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier, and StackingClassifier are ensemble techniques that improve model performance by combining multiple models.
- Metrics: For evaluating models using accuracy, classification report, ROC AUC score, and confusion matrix.
"""

# Unzipping the dataset

import zipfile
zip = zipfile.ZipFile('/content/Company_x.csv.zip')
zip.extractall('/content')
zip.close()

# Load the dataset
df1 = pd.read_csv('Company_x.csv')

"""Since Data set is big to save the execution time we will work on 20% of the data"""

# Selecting 20% of data to work on

df = df1.sample(frac=0.2)
df.head()

"""# EDA (Exploratory Data Analysis) ,Feature Engineering and Data Pre-processing ---"""

# Dataset Shape
print("Dataset Shape:", df.shape)

# General Info
print("Data Info:")
print(df.info())

"""- As we can observe there are 406423 rows and 25 columns with mixed datatypes
int, float and object.
"""

# Summary Statistics
print("\nSummary Statistics:")
print(df.describe())

# Observing the Target Variable

# checking value count
df['IsStatBarred'].value_counts()

"""--Clearly there is a class imbalance--"""

# Checking Missing Value in Target Variable

df.IsStatBarred.isnull().sum()

"""No Missing Value"""

# Visualize the distribution of the target variable

sns.countplot(x='IsStatBarred', data=df)
plt.title("Distribution of IsStatBarred")
plt.show()

# Drop unnecessary columns that are not useful for predictive modeling as these are ID numbers

df = df.drop(columns=['EntityID', 'AccountID', 'OriginalCreditor[Redacted]','Unnamed: 22', 'Unnamed: 23','Unnamed: 24'], axis=1)

# Checking the result

df.info()

"""- Approach to follow:
We will observe the individual distribution of each feature
(catrgorical and numerical both) along with it relationship with target variable to select that feature for model building.

#### Relationship Analysis: Categorical Features vs Target
"""

# Seperating Categorical Features from the Dataset

categorical_features = df.select_dtypes(include='object').columns
categorical_features

# So we have follow Categorial Variable:
# 'CurrentBalance',
# 'DebtLoadPrincipal',
# 'Balanaceatdebt_load',
# 'ProductOrDebtType',
# 'CollectionStatus',
# 'ClosureReason'
# 'InBankruptcy',
# 'AccountInsolvencyType'
# 'CustomerInsolvencyType'.
# 'IsLegal',
# 'LastPaymentAmount',
# 'LastPaymentMethod'

# We will look into them one by one

"""- Approach Followed -
  - Check and handle missing value
  - Use Count plot to observe the distribution with respect to target variable.
- Based upon the percentage of missing value and distribution with target variable we will decide whether to keep the feature for model building or not.
"""

# 1. CurrentBalance

# Checking Missing Vale

df.CurrentBalance.isnull().sum()

"""No Missing Value"""

# Checking Value Count

df.CurrentBalance.value_counts()

# Relationship with Target Variable

# sns.countplot(x='CurrentBalance', hue='IsStatBarred', data=df)
# plt.xticks(rotation=45)
# plt.show()

"""This feature has a diverse distribution with respect to target variable as it has more than 11k unique values and is likely to be kept"""

# 2. DebtLoadPrincipal

# Checking the missing values

df.DebtLoadPrincipal.isnull().sum()

"""No missing value"""

# Checkng the value count

df.DebtLoadPrincipal.value_counts()

"""We have 12k different rows hence distrubution on Target variable will be diverse so its good predictor"""

#3.Balanaceatdebt_load

# Checking Missing Value

df.Balanaceatdebt_load.isnull().sum()

"""No Missing Value"""

# Checking Value_Count

df.Balanaceatdebt_load.value_counts()

"""Similar to the features, 'CurrentBalance' and 'DebtLoadPrincipal', Balanaceatdebt_load also has 19k unique values hence distribution with the Target will be diverse hence its a good predictor so we will keep it."""

# 4. ProductOrDebtType

# Checking Missing Value

df.ProductOrDebtType.isnull().sum()

"""No Missing Value"""

# Checking the value count

df.ProductOrDebtType.value_counts()

# Relationship with Target Variable

sns.countplot(x='ProductOrDebtType', hue='IsStatBarred', data=df)
plt.xticks(rotation=45)
plt.show()

"""This feature has a diverse distribution and is likely to be kept"""

# 5.CollectionStatus

# Checking Missing Value

df.CollectionStatus.isnull().sum()

"""No missing Value"""

#Checking value count
df.CollectionStatus.value_counts()

# Relation with Target Variable
sns.countplot(x='CollectionStatus', hue='IsStatBarred', data=df)
plt.xticks(rotation=45)
plt.ylim(0, 10000)
plt.show()

"""-Categories like 'Holding', 'Pending', 'Non-Collection' has very low frequnecy we can merge then to make one-"""

# Merging HOLDING and 'PENDING' into NON_COLLECTION
df.CollectionStatus = df.CollectionStatus.replace(['HOLDING','PENDING'],'NON_COLLECTION')

# Checking the Result
df.CollectionStatus.value_counts()

"""This feature shows the variation with the target variable hence to be included in the model"""

# 6.ClosureReason

# Checking Missing Value as percentage of total rows
df.ClosureReason.isnull().sum() / df.shape[0] * 100

"""-- More than 97% of the values are missing so are dropping this column --"""

# Dropping the column
df.drop('ClosureReason', axis=1, inplace=True)

# 7. InBankruptcy

# Checking Missing Values

df.InBankruptcy.isnull().sum()

"""No Missing Value"""

# Checking Value Count

df.InBankruptcy.value_counts()

"""High Imbalance amoung the categories"""

# Relationship with Target Variable

sns.countplot(x='InBankruptcy', hue='IsStatBarred', data=df)
plt.show()

"""- It shows that people who donot file for Bankruptcy has more percentage in getting barred.This feature is highly imbalanced, but it could still be a valuable predictor depending on its relationship with the target.So we will decide to keep it for model building."""

# 8.AccountInsolvencyType

#Checking Missing Value percentage w.r.t no. of rows

df.AccountInsolvencyType.isnull().sum()/df.shape[0]*100

"""--More than 99% of the values are missing from this column has we will drop this column--"""

# Dropping the column
df.drop('AccountInsolvencyType', axis=1, inplace=True)

# 9.CustomerInsolvencyType:

# Checking Missing Value percentage w.r.t no. of rows

df.CustomerInsolvencyType.isnull().sum()/df.shape[0]*100

"""More than 97% of the values are missing so we will drop this column"""

# Dropping the column

df.drop('CustomerInsolvencyType', axis=1, inplace=True)

#10. 'IsLegal',

# Checking Missing Value

df.IsLegal.isnull().sum()

"""No Missing Value"""

# Checking Value_Count

df.IsLegal.value_counts()

# Relationship with Target Variable

sns.countplot(x = 'IsLegal',hue = 'IsStatBarred', data=df)
plt.show()

"""There is a clear difference is the distribution of both the categories on the target variable, hence Islegal is a good predictor."""

# 11.'LastPaymentAmount',

# Checking the missing value w.r.t no.of rows

df.LastPaymentAmount.isnull().sum()/df.shape[0]*100

"""Close to 75% of the value are null.Due to the high percentage of missing values, we cannot perform mean or median imputation as these values unique values we cannot fill the LastPaymentAmount as mean or median. Here we will use KNN Imputation to predict the missing values."""

# KNN Imputation for handling missing value

# Convert 'LastPaymentAmount' to numeric, handling commas

df['LastPaymentAmount'] = df['LastPaymentAmount'].str.replace(',', '').astype(float)
                                              # This step is added as we have LastPaymentAmount in the format of 1,200 so we
                                              # First convert it into string, remove ',' with '' and then conver it into float.

imputer = KNNImputer(n_neighbors=5)
df['LastPaymentAmount'] = imputer.fit_transform(df[['LastPaymentAmount']]) # .fit_transform expect a 2D array that is why
                                                                    # df[['LastPaymentAmount']] is used instead of
                                                                    # df['LastPaynentAmount']
                                        # Alternatively, we can use, df.LastPaymentAmount.values.reshape(-1,1)

# 12.LastPaymentMethod

# Checking Missing Value w.r.t No. of Rows
df.LastPaymentMethod.isnull().sum()/df.shape[0]*100

"""-- Close to 75% of the Values are missing,it could be a good predictor and provide inside info hence we will address missing.Here we will use the random sample imputation to handle missing value--"""

# Checking Value count
df.LastPaymentMethod.value_counts()

# Handing Missing Values via Random Imputation

index = df[df.LastPaymentMethod.isnull()].index
df.loc[index, 'LastPaymentMethod'] = np.random.choice(df.LastPaymentMethod.dropna().values, size=len(index))

# Checking the result

df.LastPaymentMethod.isnull().sum()

# Addtional Step to remove any extra spaces into the category name

df['LastPaymentMethod'] = df['LastPaymentMethod'].str.strip()

# Checking ValueCount post Imputation
df.LastPaymentMethod.value_counts()

# Relationship with Target Varaible

sns.countplot(x='LastPaymentMethod', hue='IsStatBarred', data = df)
plt.xticks(rotation=45)
plt.show()

"""-- Categories Like Unknown, Cash, Credit Card/ Debit Card, Direct Transfer and Master Card can be merges into one --"""

df.LastPaymentMethod.unique()

# Merging Unknown, Cash, Credit Card/ Debit Card, Direct Transfer and Master Card to make them others

df.LastPaymentMethod = df.LastPaymentMethod.replace(['Cash', 'Unknown', 'Credit Card / Debit Card', 'Mastercard','Direct Transfer'],'Others')

# Checking the Result post merging

df.LastPaymentMethod.value_counts()

"""-- Here We have completed the relationship analysis of Categorical Variable with Target variable, Now we will observe the relationship of Numerical Column with Target variable --

### Relationship Analysis of Numerical Features with Target Variable
"""

df.info()

#  Collating the Numerical Features from the Dataset

numerical_features = df.select_dtypes(exclude='object').columns

numerical_features

# We have 6 Numerical Features :
# 1.'PurchasePrice',
# 2.'NumLiableParties',
# 3.'CustomerAge',
# 4.'NumPhones',
# 5.'NumEmails',
# 6.'NumAddresses'

# Lets deal with them one by one by before that lets encode target Variable

# Encoding the target variable

df.IsStatBarred = df.IsStatBarred.map({'Y':1,'N':0})

df.IsStatBarred.value_counts()/df.shape[0]*100

"""#### Starting with Numerical Featurs
- Approach Followed -
  - Check and handle missing value
  - Check the distribution using KDE plot
  - Check the Relationship with target variable on the basis of
      - Box Plot
      - Histogram
      - Correlation
- After observing all the plot make the decision if we want to keep the numerical feature for model building or not.
"""

# 1. 'PurchasePrice'

# Checking Missing Value w.r.t to No. of Rows

df.PurchasePrice.isnull().sum()/df.shape[0]*100

"""- Less than 1% of the Value are missing, firstly observe the distribution of the column when we will decide which imputution to use to handle missing value"""

# Observing the distribution

sns.kdeplot(df.PurchasePrice)
plt.show()

"""Based on the provided KDE plot for 'PurchasePrice', the distribution appears to be right-skewed. Hence we will use median impulation as mean will be sensitive towards the outliers."""

# Finding the median of the distibution
df.PurchasePrice.median()

# Handling Missing Value using Median Imputation

df.PurchasePrice = df.PurchasePrice.fillna(df.PurchasePrice.median())

# Checking the result post medial imputation

df.PurchasePrice.isnull().sum()

# Checking the distributon after handling missing values

sns.kdeplot(df.PurchasePrice)
plt.show()

"""-Distribution is similar, no change post doing median imputation"""

# Checking the relationship with Target Variable

# 1.Using Box Plot

sns.boxplot(x='IsStatBarred', y='PurchasePrice', data=df)
plt.show()

"""The box plot shows that there is a clear difference in the median and overall distribution between the two groups `IsStatBarred` (0 and 1) is observable.  This suggests that `PurchasePrice` is likely a good predictor variable as there is a noticeable separation in the price distributions for customers who are and aren't stat barred.

"""

# 2. Using Histogram

sns.histplot(x =df.PurchasePrice, hue = df.IsStatBarred, kde=True, bins=20)
plt.show()

"""The histogram provides a more granular view of the distribution of `PurchasePrice` for each `IsStatBarred` category.  The KDE plots overlaid on the histograms further illustrate the difference in the shapes of the distributions. Similar to the box plot, the histogram confirms a difference in the distribution of purchase prices between the two categories.  The differing distributions indicate a possible relationship between `PurchasePrice` and the likelihood of being stat barred.

"""

# 3. Using Correlation

df.PurchasePrice.corr(df.IsStatBarred)

""" - There is a negative weak correlation exists between 'PurchasePrice' and 'IsStatBarred'.  This suggests that as PurchasePrice increases, the likelihood of being stat barred slightly decreases.  However, the weakness of the correlation indicates that this relationship alone might not be a strong predictor.

 - Overall Conclusion: Despite the weak correlation coefficient, the visual analysis through the histplot and box plot strongly suggests that 'PurchasePrice' is a relevant predictor for 'IsStatBarred'.  The difference in the distribution of purchase prices across the two target variable classes indicates that `PurchasePrice` could be a valuable feature in a predictive model.  While correlation provides a single numerical measure of the linear relationship, the visual representations give a more comprehensive picture of the relationship hence we will add this feature for model building.


"""

# 2.'NumLiableParties'

# Checking the missing value w.r.t. No. of Rows

df.NumLiableParties.isnull().sum()/df.shape[0]*100

"""Since 3% of values are missing, we will plot look into the distribution and then decide the imputation method for handing missing value"""

# Checking the distribution

sns.kdeplot(df.NumLiableParties)
plt.show()

"""- Based on the KDE plot for 'NumLiableParties', the distribution appears to be skewed to the right with a long tail.
- There's a concentration of values around 1, with fewer instances at higher values.
- For imputation, given the skewed distribution, using the median would be more appropriate than the mean, as the median is less sensitive to outliers.

"""

# Handling Missing Values using Median Imputation
df.NumLiableParties = df.NumLiableParties.fillna(df.NumLiableParties.median())

# Check the result
print(df.NumLiableParties.isnull().sum())

# Checking Relationship with Target Variable

#1. Using Box Plot

sns.boxplot(x='IsStatBarred', y='NumLiableParties', data=df)
plt.show()

"""The `NumLiableParties` variable shows a slight difference in the median values between the two classes of `IsStatBarred` but appears to be distributed similarly otherwise. We will observe the histplot and corr and then decide whether to keep this feature or not."""

# 2.Using Histogram

sns.histplot(x= df.NumLiableParties,hue= df.IsStatBarred, kde=True, bins=30)
plt.show()

"""The histogram provides a more granular view of the distributions. While there's a slight difference in the shape of the distributions, there is still considerable overlap, particularly at lower values of `NumLiableParties`.

"""

# 3. Using Correlation

df.NumLiableParties.corr(df.IsStatBarred)

"""- Correlation:  The correlation coefficient between 'NumLiableParties' and 'IsStatBarred' is likely to be small (close to zero based on the visual inspection).  This quantifies the weak linear relationship observed in the plots.  A near-zero correlation indicates that changes in 'NumLiableParties' do not strongly predict changes in 'IsStatBarred'.

- Based on the weak visual relationship in the boxplot and histogram, and the likely near-zero correlation, 'NumLiableParties' is probably not a very strong predictor for 'IsStatBarred'.  Including it in the model might not significantly improve its predictive power and could potentially add noise. Hence we decide to drop this feature


"""

# Dropping the feature

df.drop('NumLiableParties',axis=1,inplace=True)

# 3.CustomerAge

# Checking Missing Value w.r.t no. of rows

df.CustomerAge.isnull().sum()/df.shape[0]*100

"""Close to 7% values are missing, We will observe the distribution on Age and accordingly we will decide which imputation method to use for handling missing value"""

## CHecking the distribution

sns.kdeplot(df.CustomerAge)
plt.show()

"""Based on the KDE plot of 'CustomerAge', we can observe the following:
 - The distribution is slightly right-skewed, indicating a longer tail towards older ages.
 - The majority of customers seem to fall within a specific age range, with a peak in the distribution.
"""

# Checking Value Count

df.CustomerAge.value_counts()

df[df.CustomerAge<0]['CustomerAge'].count()

"""Based on the KDE plot and value counts, the CustomerAge distribution has a few issues:
- Missing values: ~7%
- Negative values: 20 and these are not realistic.

To handle Negetive age we will convert them into absolute value and then which ever value is less than 20 we will replace that value with median.



"""

# Handle negative ages and missing values in 'CustomerAge'

df['CustomerAge'] = df['CustomerAge'].abs() # Converting All into abs value
df['CustomerAge'] = df['CustomerAge'].apply(lambda x: df['CustomerAge'].median() if x < 20 else x) # replacing with median if Age<20

# Visualize the distribution after handling negetive age

sns.kdeplot(df.CustomerAge)
plt.show()

"""- As observed the KDE plot for Age is slightly right-skewed,hence we will use median imputation to handle missing value"""

# Perform median imputation for remaining missing values:

df.CustomerAge = df.CustomerAge.fillna(df.CustomerAge.median())

# Verify that there are no more missing values in 'CustomerAge'
print(df.CustomerAge.isnull().sum())

"""No More Missing Value"""

# Relationship with Target Variable
# 1. Using Box Plot

sns.boxplot(x='IsStatBarred', y='CustomerAge', data=df)
plt.show()

"""The box plot shows a slightly different distribution of customer ages between the two groups ('Y' and 'N' for `IsStatBarred`).  While the median ages appear relatively close, the interquartile ranges (IQRs) and the presence of outliers might differ.  This suggests a potential, though possibly weak, relationship between customer age and the likelihood of being stat barred.

"""

# 2.Using Histogram

sns.histplot(x= df.CustomerAge,hue= df.IsStatBarred, kde=True, bins=30)
plt.show()

"""The histogram plot shows slightly different distributions for customers who are stat barred (`IsStatBarred` = 1) versus those who are not (`IsStatBarred` = 0).  While there's some overlap in the distributions, the plot suggests that younger customers might be slightly more likely to be stat barred. However, the difference is not much and there's considerable overlap, indicating that `CustomerAge` alone might not be a very strong predictor of `IsStatBarred`."""

# 3.Using Correlation

df.CustomerAge.corr(df.IsStatBarred)

"""- The correlation coefficient between CustomerAge and IsStatBarred (likely to be small and possibly positive) quantifies the weak linear relationship. A small correlation implies a weak linear relationship; however, nonlinear relationships may exist.

- CustomerAge might have a weak predictive power. While the visual analysis shows some difference in distributions, the correlation coefficient indicates a weak linear relationship. For now we will decide to keep it for model building and observe the impact.


"""

# 4.NumPhones

# Checking missing value

df.NumPhones.isnull().sum()/df.shape[0]*100

"""No Missing Values"""

# Checking Value Count
df.NumPhones.value_counts()

# Checking Distribution

sns.kdeplot(df.NumPhones)

"""
The KDE plot shows a peak at 1 or a small value(0), indicating that a large portion of customers have only one phone number or either no phone associated with their account. There might be a gradual decrease in the density as the number of phones increases, suggesting fewer customers have multiple phone numbers listed.The plot could also reveal if there are any unusual spikes at higher phone number counts, indicating possible outliers.This distribution suggests that `NumPhones` might not be a very powerful predictor."""

# Relationship with Target Variable

# 1. Using BoxPlot

sns.boxplot(x = 'IsStatBarred', y='NumPhones', data=df)
plt.show()

"""- The box plot shows a clear distinction between the distribution of NumPhones for IsStatBarred = 0 (not barred) and IsStatBarred = 1 (barred).
 - IsStatBarred = 0 shows variability in NumPhones, with values ranging from 0 to 8 (with some outliers).
 - IsStatBarred = 1 is concentrated at 0, showing minimal spread.
- This separation suggests that NumPhones has potential predictive power for distinguishing between the two classes.

"""

# 2. Using Histogram

sns.histplot(x= df.NumPhones,hue= df.IsStatBarred, kde=True, bins=30)
plt.show()

"""The histogram (if similar to the distribution shown in the box plot) likely demonstrates:
 - For IsStatBarred = 0: A wider spread of NumPhones, with more frequent occurrences of higher values.
 - For IsStatBarred = 1: A sharp concentration of NumPhones at 0, indicating very low variability.
This adds further evidence that the two classes (IsStatBarred = 0 and 1) are distinguishable based on NumPhones.
"""

# 3. Using Corr

df.NumPhones.corr(df.IsStatBarred)

"""The correlation coefficient of -0.532 indicates a moderate negative correlation between NumPhones and IsStatBarred.
 - A negative correlation aligns with the observation that as NumPhones increases, the likelihood of being IsStatBarred = 1 decreases.

Based on:
 - The box plot, which shows a clear distinction between the two groups.
 - The moderate negative correlation (-0.532), suggesting a meaningful relationship between NumPhones and IsStatBarred.
 - The likely histogram distribution, highlighting different spreads for the two groups.

Conclusion:
 -NumPhones appears to be a good predictor for IsStatBarred.
"""

# 5.NumEmails

#Checking for missing values
df.NumEmails.isnull().sum()/df.shape[0]*100

"""No Missing Value"""

# Checking Value Count

df.NumEmails.value_counts()

# Checking the distribution

sns.kdeplot(df.NumEmails)
plt.show()

"""
The plot of shows a peak at 0 or a low value, indicating many customers have zero or very few associated email addresses.  The density probably decreases as the number of emails increases, suggesting fewer customers have multiple email addresses listed.  The plot might also reveal if there are any unusual spikes at higher email counts, which could indicate outliers."""

# Checking Relationship with Target

#1. Using BoxPlot

sns.boxplot(x='IsStatBarred', y='NumEmails', data=df)
plt.show()

"""The plot shows a slight difference in the distribution of the number of emails between the two groups (stat barred and not stat barred). While the medians appear relatively close, there's a noticeable difference in the spread of the data (the interquartile range or IQR) and the presence of outliers.  Specifically, the stat barred group seems to have a slightly wider spread and a higher number of outliers, indicating some customers with a large number of emails are more likely to be stat barred. However, the overall difference isn't dramatic, suggesting that while `NumEmails` might have some predictive power, it's likely not a very strong predictor on its own."""

# 2. Using Histogram

sns.histplot(x = df.NumEmails, hue= df.IsStatBarred, kde=True, bins=30)
plt.show()

"""Histogram confirms the observation from the box plot. The distributions, while overlapping, show some separation, particularly in the tails where customers with a higher number of emails might be more likely to be stat barred."""

# 3. Using Correlation

df.NumEmails.corr(df.IsStatBarred)

"""- This is a moderate negative correlation.

- While the boxplot and histogram suggest a visual difference in the distributions of NumEmails for the two classes (stat barred and not stat barred), the moderate negative correlation (-0.4027) quantifies this relationship.  A negative correlation means that as the number of emails increases, the likelihood of being stat barred decreases.  The combination of the visualizations and the correlation coefficient suggests that NumEmails is a moderately important predictor variable for IsStatBarred in predicting whether a customer is likely to be stat barred.  It's a feature worth including in your model.
"""

# 6. NumAddresses

# Checking the missing value

df.NumAddresses.isnull().sum()/df.shape[0]*100

"""No Missing Value"""

# Checking the Value Count

df.NumAddresses.value_counts()

# CHecking the distribution

sns.kdeplot(df.NumAddresses)
plt.show()

"""The KDE plot for `NumAddresses` shows a peak at a low value (likely 1), indicating that a significant portion of customers have only one address listed.  The density then decreases as the number of addresses increases, suggesting fewer customers have multiple addresses associated with their account."""

# Relationship with the Target Variable

#1. Using BoxPlot

sns.boxplot(x='IsStatBarred', y='NumAddresses', data=df)
plt.show()

"""The boxplot of shows a similar distribution of the number of addresses for both categories ('Y' and 'N' for `IsStatBarred`).  If the distributions are nearly identical, it suggests that the number of addresses a customer has is not a strong predictor of whether they are stat barred.  There might be slight differences in median or quartiles, but the overall spread and presence of outliers would likely be quite similar.

"""

# 2. Using Histogram

sns.histplot(x = df.NumAddresses, hue = df.IsStatBarred, kde=True, bins=30)
plt.show()

"""The histogram and boxplot shows very similar distributions for both groups (stat barred and not stat barred). The distributions largely overlap, indicating that the number of addresses a customer has is not a strong predictor of whether they are stat barred."""

# 3. Using Correlation

df.NumAddresses.corr(df.IsStatBarred)

"""The boxplot, histogram, and correlation coefficient all point to a weak or no relationship between the number of addresses a customer has ('NumAddresses') and whether they are stat barred ('IsStatBarred').  Visually, the distributions of 'NumAddresses' for both categories of 'IsStatBarred' are almost identical in the boxplot and histogram. The near-zero correlation coefficient further quantifies this lack of a linear relationship.

Hence 'NumAddresses' is unlikely to be a good predictor of 'IsStatBarred', So will drop this column
"""

# Dropping the column

df.drop('NumAddresses',axis=1, inplace=True)

# Checking DataFrame

df.info()

"""-- So these are our final feature on which we will build our model --"""

# Performing Label Encoding on Categorical Feature

Cat = df.select_dtypes(include='object').columns
print(Cat)

le = LabelEncoder()
for col in Cat:
    df[col] = le.fit_transform(df[col])

"""The reason for using Label Encoding instead of one hot encoding is many categorical variables (e.g., CollectionStatus, Closure Reason) may have high cardinality which may increase the no of feature and unnecessary increase the dimentionality of the model which may take more computation as we are working on 400k row data which is large itself."""

df.head()

"""# Model Building --"""

# Checking the class balance in target variable

df.IsStatBarred.value_counts()/df.shape[0]*100

"""- Here Clearly there is a class imbalance, where 70% of the class is barred and 30% is not barred.

Approach followed:
- Build different individual model on the given imbalance data and evaluate their performance
- Improve Model Performance by using follow techniques -
    - Stacking
    - Hyperparameter Tunning
    - Apply SMOTE to handle class imbalance.

## 1.Model Building on Imbalaced Class
"""

# Checking the dataset

df.head()

# Splitting the data into features (X) and target(Y)

x = df.iloc[:,:-1]
y = df.iloc[:,-1]

print(x.shape)
print(y.shape)

# Spliting the data into Train and Test

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

# Applying Standardization

ss = StandardScaler()
x_train = ss.fit_transform(x_train)
x_test = ss.transform(x_test)

"""- Approach will be firstly apply models individually and evaluate them and use ensemble technique or Hyper Parameter Tunning to improve the model performance.

Following Model will be use :
- Logistic Regression
- SVM
- Naive Bayes
- Random Forest
- Adaboost
- Gradient Boosting

Addtionally for Model Evaluation our focus will be on ROC_AUC_SCORE along with Accuracy.Why?
- Nature of Problem : This project involves predicting whether a debt is statute-barred (binary classification). The goal is to assess the probability of a positive outcome (successful debt collection). The ROC AUC Score is well-suited for such tasks because it evaluates the model's ability to distinguish between the positive and negative classes across all thresholds.



"""

# Apply Models Individually

models  = {
    'Logistic Regression' : LogisticRegression(random_state=1),
    'SVM' : SVC(probability=True, random_state =1),
    'Naive Bayes' : GaussianNB(),
    'Random Forest' : RandomForestClassifier(random_state=1),
    'Adaboost' : AdaBoostClassifier(random_state=1),
    'Gradient Boosting' : GradientBoostingClassifier(random_state=1)
}

# Training and Evaluation the models

individual_result_imb = {}

for model_name, model in models.items():
  model.fit(x_train,y_train)
  y_pred = model.predict(x_test)
  y_proba = model.predict_proba(x_test)[:, 1] if hasattr(model, "predict_proba") else None # Here hasattr() is use to check
                                                    # if the model object has any attribute name 'predict_probe' if yes it will
                                                    # execute the attribute else it will store None

  accuracy = accuracy_score(y_test,y_pred)

  roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None # Again if y_proba is not None only then it will
                                                                        # will execute else it will store None into it.
  individual_result_imb[model_name] = {'Accuracy_IMB': accuracy, 'ROC_AUC_IMB': roc_auc}

  print(f"\n{model_name} Results:")
  print("Accuracy:", accuracy)
  if roc_auc:
    print("ROC_AUC_Score:", roc_auc)
  print("Classification Report:\n", classification_report(y_test, y_pred))

# Compare Results of Individual Models ---

# Create a DataFrame for comparison of individual models
individual_results_df_imb = pd.DataFrame(individual_result_imb).T
print("\nComparison of Individual Models:\n", individual_results_df_imb.sort_values(by='ROC_AUC_IMB', ascending=False))

"""### Observation:

- Random Forest and Gradient Boosting show the highest accuracy and ROC AUC, indicating strong predictive performance on the imbalanced dataset.  They seem to be the best-performing individual models out of those tested.
- Logistic Regression has a lower accuracy compared to ensemble methods (Random Forest, Gradient Boosting, AdaBoost). Its performance is decent, but it lags behind the ensemble models.
- SVM performs reasonably well, with a ROC AUC score that is not significantly lower than the top-performing models. Its accuracy might be lower, but it still shows good discrimination between the two classes.  Its absence of a predict_proba method made it harder to evaluate the ROC_AUC.
- Adaboost shows decent performance, showing promise but not outperforming Random Forest and Gradient Boosting.  It might be worth further investigation with hyperparameter tuning or different base estimators.
- Naive Bayes underperforms compared to other models.  Its simplicity and assumptions may not align well with the characteristics of this dataset, leading to lower accuracy and ROC_AUC.  The large discrepancy between Naive Bayes's performance and the others suggests that more complex models capture the patterns in the data better.

# 2.Techniques to Improve Model Accuracy
Here we will implement 3 techniques
1. Ensemble Technique (Stacking Classifier)
2. HyperParameter Tunning on Top Model amoung the individual models
3. Using SMOTE technique to handle imbalance data and then build individual models again and evaluate them
"""

# 1. Applying Stacking Ensemble Model ---

# Stacking Classifier
stacking_model = StackingClassifier(
    estimators=[
        ('rf', RandomForestClassifier(random_state=42)),
        ('gb', GradientBoostingClassifier(random_state=42)),
        ('svm', SVC(probability=True, random_state=42))
    ],
    final_estimator=LogisticRegression()
)

# Train the stacking model
stacking_model.fit(x_train, y_train)

# Evaluate the stacking model
y_pred_stack = stacking_model.predict(x_test)
y_proba_stack = stacking_model.predict_proba(x_test)[:, 1]
acc_stack = accuracy_score(y_test, y_pred_stack)
roc_auc_stack = roc_auc_score(y_test, y_proba_stack)

print("\nStacking Classifier Results:")
print("Accuracy:", acc_stack)
print("ROC AUC Score:", roc_auc_stack)
print("Classification Report:\n", classification_report(y_test, y_pred_stack))

# Compare Results of Stacking vs Individual Models ---

# Add Stacking results to the comparison DataFrame

individual_results_df_imb.loc['Stacking Classifier'] = {'Accuracy_IMB': acc_stack, 'ROC_AUC_IMB': roc_auc_stack}

# Final Comparison of All Models

print("\nFinal Comparison of All Models (Including Stacking):\n", individual_results_df_imb.sort_values(by='ROC_AUC_IMB', ascending=False))

"""- Clearly Stacking Ensemble has improved the accuracy and ROC_AUC Score"""

# 2.Hyperparameter Tuning for the Best Model ---

# Select the best model based on ROC AUC (we are considering ROC AUC not accuracy because we are working on imbalance data so
# Accuracy is not reliable measure for model evaluation)
# For imbalanced datasets, ROC_AUC score is generally a better evaluation metric than accuracy
# because it evaluates the model's ability to distinguish between the classes without being biased by class imbalances.

best_model_name = individual_results_df_imb['ROC_AUC_IMB'].idxmax()  # Find the model with highest ROC AUC

# Check if the best model is the Stacking Classifier
if best_model_name == 'Stacking Classifier':
    best_model = stacking_model  # Use the stacking_model if it's the best
else:
    best_model = models[best_model_name]  # Otherwise, use the model from the models dictionary

print(f"\nBest Model: {best_model_name}")

"""So the best model is obviously the Stacking Classifier based on ROC_AUC_Score since its ensemble technque which we have used to improve the model performance, our focus will be on individual model and the best individual model after Stacking Technique is Random Forest on the basis of ROC_AUC_SCORE,so now we will perform hyperparameter tunning on Random Forest to see if model performance can be improved."""

# Hyperparameter tuning for the best individual model,Random Forest

param_grid_rf = {
        'n_estimators': [100, 200],
        'max_depth': [10, 20],
        'min_samples_split': [2, 5],
        'min_samples_leaf': [1, 2]
    }

grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=1),
                              param_grid_rf,
                              cv=3,
                              scoring='roc_auc',
                              n_jobs=-1)

grid_search_rf.fit(x_train, y_train)

print("Best Parameters for Random Forest:", grid_search_rf.best_params_)

# Using the best_params to fit a model

best_rf_model = grid_search_rf.best_estimator_
y_pred_rf = best_rf_model.predict(x_test)
print("\nBest Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# Evaluate Best Model Performance ---

# Confusion matrix for the best model

from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_estimator(best_rf_model, x_test, y_test)
plt.title(f"Confusion Matrix for {best_model_name}")
plt.show()

# Conclusion #
# Display the best performing model based on ROC AUC or accuracy

print('Random Forest Performance Before Hyper Parameter Tunning:')
print(individual_results_df_imb.loc['Random Forest'])


print('\nRandom Forest Performance After Hyper Parameter Tunning:')
print('Accuracy:', accuracy_score(y_pred,y_pred_rf))
print("ROC_AUC_Score:", roc_auc_score(y_test, y_pred_rf))

"""As we can observe the accuracy has been increase however the roc_auc scroe is decreased a bit"""

# 3. Apply SMOTE Techninue for Imbalance Data

smote = SMOTE(random_state=1)
x_resampled, y_resampled = smote.fit_resample(x_train, y_train)

# Check class distribution after SMOTE
print("Class distribution after SMOTE:", pd.Series(y_resampled).value_counts())

# Checking Individual Model Performance After SMOTE

models  = {
    'Logistic Regression' : LogisticRegression(random_state=1),
    'SVM' : SVC(probability=True, random_state =1),
    'Naive Bayes' : GaussianNB(),
    'Random Forest' : RandomForestClassifier(random_state=1),
    'Adaboost' : AdaBoostClassifier(random_state=1),
    'Gradient Boosting' : GradientBoostingClassifier(random_state=1)
}

# Training and Evaluation the models

individual_result = {}

for model_name, model in models.items():
  model.fit(x_resampled,y_resampled)
  y_pred = model.predict(x_test)
  y_proba = model.predict_proba(x_test)[:, 1] if hasattr(model, "predict_proba") else None # Here hasattr() is use to check
                                                    # if the model object has any attribute name 'predict_probe' if yes it will
                                                    # execute the attribute else it will store None

  accuracy = accuracy_score(y_test,y_pred)

  roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None # Again if y_proba is not None only then it will
                                                                            # will execute else it will store None into it.
  individual_result[model_name] = {'Accuracy': accuracy, 'ROC AUC': roc_auc}

  print(f"\n{model_name} Results:")
  print("Accuracy:", accuracy)
  if roc_auc:
    print("ROC AUC Score:", roc_auc)
  print("Classification Report:\n", classification_report(y_test, y_pred))

# Compare Results of Individual Models ---
# Create a DataFrame for comparison of individual models
individual_results_df = pd.DataFrame(individual_result).T
print("\nComparison of Individual Models After SMOTE:\n", individual_results_df.sort_values(by='ROC AUC', ascending=False))

print("\nComparison of Individual Models Before SMOTE:\n",individual_results_df_imb.sort_values(by='ROC_AUC_IMB', ascending=False))

# Comparing the individual model performance before and after SMOTE :

# Concatinating Both Datasets

compare_df = pd.concat([individual_results_df_imb,individual_results_df],axis=1)

# Rearranging the columns
compare_df = compare_df.reindex(columns=['Accuracy_IMB','Accuracy','ROC_AUC_IMB','ROC AUC'])

# Renaming the columns for better framing
compare_df = compare_df.rename(columns={'Accuracy_IMB':'Acc_Imb',
                                        'Accuracy':'Acc_SMOTE',
                                        'ROC_AUC_IMB':'ROC_AUC_Imb',
                                        'ROC AUC':'ROC_AUC_SMOTE'})

# Arranging the column on the basis of highest ROC_AUC Score After SMOTE in Descending Order:

print("\nComparison of Individual Models Before and After SMOTE on the basis of Highest ROC_AUC Score Post SMOTE:\n\n",compare_df.sort_values(by='ROC_AUC_SMOTE', ascending=False))

# Comparing the result of each model parameters before and after applying SMOTE

print("\nObservations on Model Performance:")
for model in compare_df.index[0:-1]:
  print(f"\nModel: {model}")
  accuracy_diff = compare_df.loc[model, 'Acc_SMOTE'] - compare_df.loc[model, 'Acc_Imb']
  roc_auc_diff = compare_df.loc[model, 'ROC_AUC_SMOTE'] - compare_df.loc[model, 'ROC_AUC_Imb']
  print(f"- Accuracy Difference (SMOTE - Imbalanced): {accuracy_diff:.4f}")
  print(f"- ROC AUC Difference (SMOTE - Imbalanced): {roc_auc_diff:.4f}")
  if accuracy_diff > 0:
    print("- Accuracy improved after SMOTE.")
  elif accuracy_diff < 0:
    print("- Accuracy decreased after SMOTE.")
  else:
    print("- Accuracy remained the same after SMOTE.")

  if roc_auc_diff > 0:
    print("- ROC AUC improved after SMOTE.")
  elif roc_auc_diff < 0:
      print("- ROC AUC decreased after SMOTE.")
  else:
    print("- ROC AUC remained the same after SMOTE.")

# Visual Representaion of Model Comparison

df = compare_df[:-1]

# Plot setup
x = np.arange(len(df["Model"]))  # the label locations
width = 0.2  # the width of the bars

fig, ax = plt.subplots(figsize=(12, 6))

# Bar plots
bars1 = ax.bar(x - 1.5*width, df["Acc_Imb"], width, label="Accuracy (Imbalanced)", color='skyblue')
bars2 = ax.bar(x - 0.5*width, df["Acc_SMOTE"], width, label="Accuracy (SMOTE)", color='lightgreen')
bars3 = ax.bar(x + 0.5*width, df["ROC_AUC_Imb"], width, label="ROC AUC (Imbalanced)", color='orange')
bars4 = ax.bar(x + 1.5*width, df["ROC_AUC_SMOTE"], width, label="ROC AUC (SMOTE)", color='red')

# Add labels and customizations
ax.set_xlabel("Models", fontsize=12)
ax.set_ylabel("Scores", fontsize=12)
ax.set_title("Comparison of Model Performance Before and After SMOTE", fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(df["Model"], rotation=30, fontsize=10)
ax.legend(loc='lower right', fontsize=10)
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.tight_layout()
plt.show()

"""Observations:
- Logistic Regression, SVM, Naive Bayes, and Adaboost performed better with SMOTE in terms of ROC AUC, which is an essential metric for imbalanced data because it captures the trade-off between true positive rate (TPR) and false positive rate (FPR).
- Random Forest and Gradient Boosting did not benefit from SMOTE, likely because these models already have mechanisms to handle imbalanced data effectively (e.g., weighted splits and ensemble techniques).
- Overall Performance: While SMOTE improved the ROC AUC for some models, it did not significantly benefit Random Forest, and in some cases, it even slightly decreased performance.  The Random Forest model after hyperparameter tuning already demonstrated good performance on the imbalanced dataset.  Stacking provides a marginal increase in performance.
- Robustness:  Random Forest generally handles class imbalance better than many other models. Its internal mechanisms help to address the issue without the need for oversampling.
- Interpretability: Random Forest models offer good interpretability
compared to more complex ensemble techniques, such as Stacking. This
can be beneficial for explaining model predictions to stakeholders.
- Computational Cost:  Avoid SMOTE unless strictly necessary. It increases the size of the dataset, which can lead to longer training times without guaranteed improvement in performance.
- Tuning: Hyperparameter tuning has already been applied to the Random Forest, showing a potential for improvement over the base model.

#### In summary, the *Random Forest* model with hyperparameter tuning provides a good balance between performance, robustness, and computational efficiency for this imbalanced dataset.
"""

